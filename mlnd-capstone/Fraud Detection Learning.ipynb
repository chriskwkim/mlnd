{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning, Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from altair.vega import v5\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        #else:\n",
    "            #df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train identity:(144233, 41)\n",
      "Train transaction:(590540, 394)\n"
     ]
    }
   ],
   "source": [
    "train_identity = pd.read_csv('data/train_identity.csv')\n",
    "print(\"Train identity:{}\".format(train_identity.shape))\n",
    "train_transaction = pd.read_csv('data/train_transaction.csv')\n",
    "print(\"Train transaction:{}\".format(train_transaction.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 45.12 MB --> 25.86 MB (Decreased by 42.7%)\n",
      "Memory usage of dataframe is 1775.15 MB --> 542.35 MB (Decreased by 69.4%)\n"
     ]
    }
   ],
   "source": [
    "train_identity = reduce_mem_usage(train_identity)\n",
    "train_transaction = reduce_mem_usage(train_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung browser 6.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2220x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ...                id_31  id_32  \\\n",
       "0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n",
       "2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n",
       "\n",
       "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n",
       "0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "4  2220x1080  match_status:2      T     F     T      T      mobile   \n",
       "\n",
       "                      DeviceInfo  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4  SAMSUNG SM-G892A Build/NRD90M  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join Transaction and Identity dataframes\n",
    "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete identity and transaction dataframes from memory\n",
    "del train_identity, train_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://localhost:8888/notebooks/IEEE-CIS%20Fraud%20Detection%20_%20EDA.ipynb\n",
    "import datetime\n",
    "\n",
    "START_DATE = '2017-11-30'\n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "train['Date'] = train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "train['_ymd'] = train['Date'].dt.year.astype(str) + '-' + train['Date'].dt.month.astype(str) + '-' + train['Date'].dt.day.astype(str)\n",
    "train['_year_month'] = train['Date'].dt.year.astype(str) + '-' + train['Date'].dt.month.astype(str)\n",
    "train['_weekday'] = train['Date'].dt.dayofweek\n",
    "train['_hour'] = train['Date'].dt.hour\n",
    "train['_day'] = train['Date'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt\n",
    "# id_30 OS\n",
    "train.loc[train['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\n",
    "train.loc[train['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\n",
    "train.loc[train['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\n",
    "train.loc[train['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\n",
    "train['id_30'].fillna(\"NAN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAN        512975\n",
       "Windows     36739\n",
       "iOS         19782\n",
       "Mac         13580\n",
       "Android      6303\n",
       "Linux        1136\n",
       "other          15\n",
       "func           10\n",
       "Name: id_30, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id_30'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAN        450258\n",
       "Chrome      76059\n",
       "Safari      37281\n",
       "IE          10018\n",
       "Firefox      7012\n",
       "Edge         6401\n",
       "Samsung      2044\n",
       "Others        706\n",
       "Opera         449\n",
       "other         312\n",
       "Name: id_31, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt\n",
    "# id_31 Browser\n",
    "train.loc[train['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\n",
    "train.loc[train['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\n",
    "train.loc[train['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\n",
    "train.loc[train['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\n",
    "train.loc[train['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\n",
    "train.loc[train['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\n",
    "train.loc[train['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\n",
    "train['id_31'].fillna(\"NAN\", inplace=True)\n",
    "train.loc[train.id_31.isin(train.id_31.value_counts()[train.id_31.value_counts() < 200].index), 'id_31'] = \"Others\"\n",
    "train['id_31'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n",
    "          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n",
    "          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n",
    "          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n",
    "          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n",
    "          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n",
    "          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n",
    "          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n",
    "          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n",
    "          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n",
    "          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n",
    "          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n",
    "          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n",
    "          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n",
    "          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n",
    "          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n",
    "          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n",
    "          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n",
    "          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n",
    "\n",
    "us_emails = ['gmail', 'net', 'edu']\n",
    "\n",
    "# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100499#latest-579654\n",
    "for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "    train[c + '_bin'] = train[c].map(emails)\n",
    "    \n",
    "    train[c + '_suffix'] = train[c].map(lambda x: str(x).split('.')[-1])\n",
    "    \n",
    "    train[c + '_suffix'] = train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google         228851\n",
       "yahoo          109149\n",
       "microsoft       59477\n",
       "other           52868\n",
       "aol             28604\n",
       "apple            8225\n",
       "att              7210\n",
       "spectrum         1046\n",
       "centurylink       654\n",
       "Name: P_emaildomain_bin, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['P_emaildomain_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com    466477\n",
       "nan     94456\n",
       "us      25038\n",
       "mx       2499\n",
       "es        877\n",
       "de        506\n",
       "fr        494\n",
       "uk        161\n",
       "jp         32\n",
       "Name: P_emaildomain_suffix, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['P_emaildomain_suffix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('TransactionID', axis=1, inplace=True)\n",
    "train.drop('TransactionDT', axis=1, inplace=True)\n",
    "train.drop('_ymd', axis=1, inplace=True)\n",
    "train.drop('_year_month', axis=1, inplace=True)\n",
    "train.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', \n",
    "            'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', \n",
    "            'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n",
    "            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', \n",
    "            'M8', 'M9', 'P_emaildomain_bin', 'P_emaildomain_suffix', 'R_emaildomain_bin', 'R_emaildomain_suffix']\n",
    "for col in cat_cols:\n",
    "    if col in train.columns:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isFraud\n",
      "TransactionAmt\n",
      "ProductCD\n",
      "card1\n",
      "card2\n",
      "card3\n",
      "card4\n",
      "card5\n",
      "card6\n",
      "addr1\n",
      "addr2\n",
      "dist1\n",
      "dist2\n",
      "P_emaildomain\n",
      "R_emaildomain\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "C4\n",
      "C5\n",
      "C6\n",
      "C7\n",
      "C8\n",
      "C9\n",
      "C10\n",
      "C11\n",
      "C12\n",
      "C13\n",
      "C14\n",
      "D1\n",
      "D2\n",
      "D3\n",
      "D4\n",
      "D5\n",
      "D6\n",
      "D7\n",
      "D8\n",
      "D9\n",
      "D10\n",
      "D11\n",
      "D12\n",
      "D13\n",
      "D14\n",
      "D15\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "M7\n",
      "M8\n",
      "M9\n",
      "V1\n",
      "V2\n",
      "V3\n",
      "V4\n",
      "V5\n",
      "V6\n",
      "V7\n",
      "V8\n",
      "V9\n",
      "V10\n",
      "V11\n",
      "V12\n",
      "V13\n",
      "V14\n",
      "V15\n",
      "V16\n",
      "V17\n",
      "V18\n",
      "V19\n",
      "V20\n",
      "V21\n",
      "V22\n",
      "V23\n",
      "V24\n",
      "V25\n",
      "V26\n",
      "V27\n",
      "V28\n",
      "V29\n",
      "V30\n",
      "V31\n",
      "V32\n",
      "V33\n",
      "V34\n",
      "V35\n",
      "V36\n",
      "V37\n",
      "V38\n",
      "V39\n",
      "V40\n",
      "V41\n",
      "V42\n",
      "V43\n",
      "V44\n",
      "V45\n",
      "V46\n",
      "V47\n",
      "V48\n",
      "V49\n",
      "V50\n",
      "V51\n",
      "V52\n",
      "V53\n",
      "V54\n",
      "V55\n",
      "V56\n",
      "V57\n",
      "V58\n",
      "V59\n",
      "V60\n",
      "V61\n",
      "V62\n",
      "V63\n",
      "V64\n",
      "V65\n",
      "V66\n",
      "V67\n",
      "V68\n",
      "V69\n",
      "V70\n",
      "V71\n",
      "V72\n",
      "V73\n",
      "V74\n",
      "V75\n",
      "V76\n",
      "V77\n",
      "V78\n",
      "V79\n",
      "V80\n",
      "V81\n",
      "V82\n",
      "V83\n",
      "V84\n",
      "V85\n",
      "V86\n",
      "V87\n",
      "V88\n",
      "V89\n",
      "V90\n",
      "V91\n",
      "V92\n",
      "V93\n",
      "V94\n",
      "V95\n",
      "V96\n",
      "V97\n",
      "V98\n",
      "V99\n",
      "V100\n",
      "V101\n",
      "V102\n",
      "V103\n",
      "V104\n",
      "V105\n",
      "V106\n",
      "V107\n",
      "V108\n",
      "V109\n",
      "V110\n",
      "V111\n",
      "V112\n",
      "V113\n",
      "V114\n",
      "V115\n",
      "V116\n",
      "V117\n",
      "V118\n",
      "V119\n",
      "V120\n",
      "V121\n",
      "V122\n",
      "V123\n",
      "V124\n",
      "V125\n",
      "V126\n",
      "V127\n",
      "V128\n",
      "V129\n",
      "V130\n",
      "V131\n",
      "V132\n",
      "V133\n",
      "V134\n",
      "V135\n",
      "V136\n",
      "V137\n",
      "V138\n",
      "V139\n",
      "V140\n",
      "V141\n",
      "V142\n",
      "V143\n",
      "V144\n",
      "V145\n",
      "V146\n",
      "V147\n",
      "V148\n",
      "V149\n",
      "V150\n",
      "V151\n",
      "V152\n",
      "V153\n",
      "V154\n",
      "V155\n",
      "V156\n",
      "V157\n",
      "V158\n",
      "V159\n",
      "V160\n",
      "V161\n",
      "V162\n",
      "V163\n",
      "V164\n",
      "V165\n",
      "V166\n",
      "V167\n",
      "V168\n",
      "V169\n",
      "V170\n",
      "V171\n",
      "V172\n",
      "V173\n",
      "V174\n",
      "V175\n",
      "V176\n",
      "V177\n",
      "V178\n",
      "V179\n",
      "V180\n",
      "V181\n",
      "V182\n",
      "V183\n",
      "V184\n",
      "V185\n",
      "V186\n",
      "V187\n",
      "V188\n",
      "V189\n",
      "V190\n",
      "V191\n",
      "V192\n",
      "V193\n",
      "V194\n",
      "V195\n",
      "V196\n",
      "V197\n",
      "V198\n",
      "V199\n",
      "V200\n",
      "V201\n",
      "V202\n",
      "V203\n",
      "V204\n",
      "V205\n",
      "V206\n",
      "V207\n",
      "V208\n",
      "V209\n",
      "V210\n",
      "V211\n",
      "V212\n",
      "V213\n",
      "V214\n",
      "V215\n",
      "V216\n",
      "V217\n",
      "V218\n",
      "V219\n",
      "V220\n",
      "V221\n",
      "V222\n",
      "V223\n",
      "V224\n",
      "V225\n",
      "V226\n",
      "V227\n",
      "V228\n",
      "V229\n",
      "V230\n",
      "V231\n",
      "V232\n",
      "V233\n",
      "V234\n",
      "V235\n",
      "V236\n",
      "V237\n",
      "V238\n",
      "V239\n",
      "V240\n",
      "V241\n",
      "V242\n",
      "V243\n",
      "V244\n",
      "V245\n",
      "V246\n",
      "V247\n",
      "V248\n",
      "V249\n",
      "V250\n",
      "V251\n",
      "V252\n",
      "V253\n",
      "V254\n",
      "V255\n",
      "V256\n",
      "V257\n",
      "V258\n",
      "V259\n",
      "V260\n",
      "V261\n",
      "V262\n",
      "V263\n",
      "V264\n",
      "V265\n",
      "V266\n",
      "V267\n",
      "V268\n",
      "V269\n",
      "V270\n",
      "V271\n",
      "V272\n",
      "V273\n",
      "V274\n",
      "V275\n",
      "V276\n",
      "V277\n",
      "V278\n",
      "V279\n",
      "V280\n",
      "V281\n",
      "V282\n",
      "V283\n",
      "V284\n",
      "V285\n",
      "V286\n",
      "V287\n",
      "V288\n",
      "V289\n",
      "V290\n",
      "V291\n",
      "V292\n",
      "V293\n",
      "V294\n",
      "V295\n",
      "V296\n",
      "V297\n",
      "V298\n",
      "V299\n",
      "V300\n",
      "V301\n",
      "V302\n",
      "V303\n",
      "V304\n",
      "V305\n",
      "V306\n",
      "V307\n",
      "V308\n",
      "V309\n",
      "V310\n",
      "V311\n",
      "V312\n",
      "V313\n",
      "V314\n",
      "V315\n",
      "V316\n",
      "V317\n",
      "V318\n",
      "V319\n",
      "V320\n",
      "V321\n",
      "V322\n",
      "V323\n",
      "V324\n",
      "V325\n",
      "V326\n",
      "V327\n",
      "V328\n",
      "V329\n",
      "V330\n",
      "V331\n",
      "V332\n",
      "V333\n",
      "V334\n",
      "V335\n",
      "V336\n",
      "V337\n",
      "V338\n",
      "V339\n",
      "id_01\n",
      "id_02\n",
      "id_03\n",
      "id_04\n",
      "id_05\n",
      "id_06\n",
      "id_07\n",
      "id_08\n",
      "id_09\n",
      "id_10\n",
      "id_11\n",
      "id_12\n",
      "id_13\n",
      "id_14\n",
      "id_15\n",
      "id_16\n",
      "id_17\n",
      "id_18\n",
      "id_19\n",
      "id_20\n",
      "id_21\n",
      "id_22\n",
      "id_23\n",
      "id_24\n",
      "id_25\n",
      "id_26\n",
      "id_27\n",
      "id_28\n",
      "id_29\n",
      "id_30\n",
      "id_31\n",
      "id_32\n",
      "id_33\n",
      "id_34\n",
      "id_35\n",
      "id_36\n",
      "id_37\n",
      "id_38\n",
      "DeviceType\n",
      "DeviceInfo\n",
      "_weekday\n",
      "_hour\n",
      "_day\n",
      "P_emaildomain_bin\n",
      "P_emaildomain_suffix\n",
      "R_emaildomain_bin\n",
      "R_emaildomain_suffix\n"
     ]
    }
   ],
   "source": [
    "# iterating the columns \n",
    "for col in train.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['isFraud']\n",
    "X = train.drop('isFraud', axis=1)\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "      <th>_weekday</th>\n",
       "      <th>_hour</th>\n",
       "      <th>_day</th>\n",
       "      <th>P_emaildomain_bin</th>\n",
       "      <th>P_emaildomain_suffix</th>\n",
       "      <th>R_emaildomain_bin</th>\n",
       "      <th>R_emaildomain_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>59.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>9638</td>\n",
       "      <td>233</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1742</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191582</th>\n",
       "      <td>23.3750</td>\n",
       "      <td>0</td>\n",
       "      <td>8788</td>\n",
       "      <td>195</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1742</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260168</th>\n",
       "      <td>35.9375</td>\n",
       "      <td>4</td>\n",
       "      <td>2250</td>\n",
       "      <td>167</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>282</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1742</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18516</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>10436</td>\n",
       "      <td>482</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1598</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47538</th>\n",
       "      <td>75.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>5226</td>\n",
       "      <td>413</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 438 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionAmt  ProductCD  card1  card2  card3  card4  card5  card6  \\\n",
       "5307           59.0000          4   9638    233     42      4    108      2   \n",
       "191582         23.3750          0   8788    195     73      4    108      1   \n",
       "260168         35.9375          4   2250    167     42      4     58      2   \n",
       "18516         100.0000          2  10436    482     42      4    108      1   \n",
       "47538          75.0000          1   5226    413     42      2      2      1   \n",
       "\n",
       "        addr1  addr2  ...  id_38  DeviceType  DeviceInfo  _weekday  _hour  \\\n",
       "5307      166     65  ...      2           2        1742         5      0   \n",
       "191582    332     74  ...      0           0        1742         3     18   \n",
       "260168    282     65  ...      2           2        1742         5      2   \n",
       "18516      17     65  ...      0           0        1598         1     18   \n",
       "47538     173     65  ...      1           1        1297         2      0   \n",
       "\n",
       "        _day  P_emaildomain_bin  P_emaildomain_suffix  R_emaildomain_bin  \\\n",
       "5307       2                  4                     0                  6   \n",
       "191582    18                  4                     0                  4   \n",
       "260168    10                  4                     0                  6   \n",
       "18516      5                  9                     8                  9   \n",
       "47538     13                  4                     0                  4   \n",
       "\n",
       "        R_emaildomain_suffix  \n",
       "5307                       6  \n",
       "191582                     0  \n",
       "260168                     6  \n",
       "18516                      8  \n",
       "47538                      0  \n",
       "\n",
       "[5 rows x 438 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(y_test, y_pred):\n",
    "    tp_count = 0\n",
    "    fp_count = 0\n",
    "    tn_count = 0\n",
    "    fn_count = 0\n",
    "\n",
    "    y_t = np.array(y_test)\n",
    "    count = y_t.size\n",
    "\n",
    "    for i in range(y_t.size):\n",
    "        if y_t[i] == 1 and y_pred[i] == 1:\n",
    "            tp_count += 1\n",
    "        elif y_t[i] == 1 and y_pred[i] == 0:\n",
    "            fn_count += 1\n",
    "        elif y_t[i] == 0 and y_pred[i] == 1:\n",
    "            fp_count += 1\n",
    "        elif y_t[i] == 0 and y_pred[i] == 0:\n",
    "            tn_count += 1\n",
    "\n",
    "    print (\"true positive {0}, false positive: {1}, false negative: {2}, true negative: {3}\"\n",
    "          .format(tp_count, fp_count, fn_count, tn_count))\n",
    "\n",
    "    precision = tp_count / (tp_count + fp_count)\n",
    "    recall = tp_count / (tp_count + fn_count)\n",
    "\n",
    "    print (\"Precision: {0}, Recall: {1}\".format(precision, recall))\n",
    "\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    print (\"F1 score: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive 2514, false positive: 3015, false negative: 1728, true negative: 110851\n",
      "Precision: 0.4546934346174715, Recall: 0.5926449787835927\n",
      "F1 score: 0.5145839729812712\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "show_scores(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 4s, sys: 2min 8s, total: 3h 2min 12s\n",
      "Wall time: 16min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "params={'learning_rate': 0.01,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_threads': -1,\n",
    "        'num_leaves': 256,\n",
    "        'verbose': 1,\n",
    "        'random_state': 42,\n",
    "        'bagging_fraction': 1,\n",
    "        'feature_fraction': 0.85\n",
    "       }\n",
    "\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "sub_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "clf = lgb.LGBMClassifier(**params, n_estimators=3000)\n",
    "clf.fit(X_train, y_train)\n",
    "oof_preds = clf.predict_proba(X_train, num_iteration=clf.best_iteration_)[:,1]\n",
    "sub_preds = clf.predict_proba(X_test, num_iteration=clf.best_iteration_)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, oof_preds)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive 2451, false positive: 50, false negative: 1791, true negative: 113816\n",
      "Precision: 0.9800079968012795, Recall: 0.5777934936350778\n",
      "F1 score: 0.7269761233872164\n"
     ]
    }
   ],
   "source": [
    "sub_preds.size\n",
    "y_preds = [0 if pred < 0.5 else 1 for pred in sub_preds]\n",
    "y_preds\n",
    "show_scores(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import make_scorer\n",
    "## Hyperopt modules\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
    "from functools import partial\n",
    "\n",
    "import time\n",
    "def objective(params):\n",
    "    time1 = time.time()\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'gamma': \"{:.3f}\".format(params['gamma']),\n",
    "        'subsample': \"{:.2f}\".format(params['subsample']),\n",
    "        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n",
    "        'reg_lambda': \"{:.3f}\".format(params['reg_lambda']),\n",
    "        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n",
    "        'num_leaves': '{:.3f}'.format(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'min_child_samples': '{:.3f}'.format(params['min_child_samples']),\n",
    "        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n",
    "        'bagging_fraction': '{:.3f}'.format(params['bagging_fraction'])\n",
    "    }\n",
    "\n",
    "    print(\"\\n############## New Run ################\")\n",
    "    print(f\"params = {params}\")\n",
    "    FOLDS = 7\n",
    "    count=1\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    tss = TimeSeriesSplit(n_splits=FOLDS)\n",
    "    y_preds = np.zeros(y_test.shape[0])\n",
    "    y_oof = np.zeros(X_train.shape[0])\n",
    "    score_mean = 0\n",
    "    for tr_idx, val_idx in tss.split(X_train, y_train):\n",
    "        clf = xgb.XGBClassifier(\n",
    "            n_estimators=600, random_state=4, verbose=True, \n",
    "            tree_method='gpu_hist', \n",
    "            **params\n",
    "        )\n",
    "\n",
    "        X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        clf.fit(X_tr, y_tr)\n",
    "        #y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "        #print(y_pred_train)\n",
    "        score = make_scorer(roc_auc_score, needs_proba=True)(clf, X_vl, y_vl)\n",
    "        # plt.show()\n",
    "        score_mean += score\n",
    "        print(f'{count} CV - score: {round(score, 4)}')\n",
    "        count += 1\n",
    "    time2 = time.time() - time1\n",
    "    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n",
    "    gc.collect()\n",
    "    print(f'Mean ROC_AUC: {score_mean / FOLDS}')\n",
    "    del X_tr, X_vl, y_tr, y_vl, clf, score\n",
    "    return -(score_mean / FOLDS)\n",
    "\n",
    "\n",
    "space = {\n",
    "    # The maximum depth of a tree, same as GBM.\n",
    "    # Used to control over-fitting as higher depth will allow model \n",
    "    # to learn relations very specific to a particular sample.\n",
    "    # Should be tuned using CV.\n",
    "    # Typical values: 3-10\n",
    "    'max_depth': hp.quniform('max_depth', 7, 23, 1),\n",
    "    \n",
    "    # reg_alpha: L1 regularization term. L1 regularization encourages sparsity \n",
    "    # (meaning pulling weights to 0). It can be more useful when the objective\n",
    "    # is logistic regression since you might need help with feature selection.\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    \n",
    "    # reg_lambda: L2 regularization term. L2 encourages smaller weights, this\n",
    "    # approach can be more useful in tree-models where zeroing \n",
    "    # features might not make much sense.\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    \n",
    "    # eta: Analogous to learning rate in GBM\n",
    "    # Makes the model more robust by shrinking the weights on each step\n",
    "    # Typical final values to be used: 0.01-0.2\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    \n",
    "    # colsample_bytree: Similar to max_features in GBM. Denotes the \n",
    "    # fraction of columns to be randomly samples for each tree.\n",
    "    # Typical values: 0.5-1\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
    "    \n",
    "    # A node is split only when the resulting split gives a positive\n",
    "    # reduction in the loss function. Gamma specifies the \n",
    "    # minimum loss reduction required to make a split.\n",
    "    # Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    \n",
    "    # more increases accuracy, but may lead to overfitting.\n",
    "    # num_leaves: the number of leaf nodes to use. Having a large number \n",
    "    # of leaves will improve accuracy, but will also lead to overfitting.\n",
    "    'num_leaves': hp.choice('num_leaves', list(range(20, 250, 10))),\n",
    "    \n",
    "    # specifies the minimum samples per leaf node.\n",
    "    # the minimum number of samples (data) to group into a leaf. \n",
    "    # The parameter can greatly assist with overfitting: larger sample\n",
    "    # sizes per leaf will reduce overfitting (but may lead to under-fitting).\n",
    "    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n",
    "    \n",
    "    # subsample: represents a fraction of the rows (observations) to be \n",
    "    # considered when building each subtree. Tianqi Chen and Carlos Guestrin\n",
    "    # in their paper A Scalable Tree Boosting System recommend \n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    \n",
    "    # randomly select a fraction of the features.\n",
    "    # feature_fraction: controls the subsampling of features used\n",
    "    # for training (as opposed to subsampling the actual training data in \n",
    "    # the case of bagging). Smaller fractions reduce overfitting.\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
    "    \n",
    "    # randomly bag or subsample training data.\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
    "    \n",
    "    # bagging_fraction and bagging_freq: enables bagging (subsampling) \n",
    "    # of the training data. Both values need to be set for bagging to be used.\n",
    "    # The frequency controls how often (iteration) bagging is used. Smaller\n",
    "    # fractions and frequencies reduce overfitting.\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "############## New Run ################\n",
      "params = {'max_depth': 17, 'gamma': '0.593', 'subsample': '0.40', 'reg_alpha': '0.166', 'reg_lambda': '0.199', 'learning_rate': '0.069', 'num_leaves': '110.000', 'colsample_bytree': '0.821', 'min_child_samples': '230.000', 'feature_fraction': '0.640', 'bagging_fraction': '0.867'}\n",
      "  0%|          | 0/27 [00:00<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[20:43:33] src/learner.cc:180: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1e2cf579 dmlc::LogMessageFatal::~LogMessageFatal() + 57\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1e2d2e70 xgboost::LearnerImpl::ConfigureUpdaters() + 2016\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1e2ca971 xgboost::LearnerImpl::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 3633\n  [bt] (3) 4   libxgboost.dylib                    0x0000001a1e2ea2eb XGBoosterUpdateOneIter + 139\n  [bt] (4) 5   libffi.6.dylib                      0x000000010db6b884 ffi_call_unix64 + 76\n  [bt] (5) 6   ???                                 0x00007ffee2c21770 0x0 + 140732702791536\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-b74ada5ad767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             max_evals=27)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-81001adf462a>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m#y_pred_train = clf.predict_proba(X_vl)[:,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#print(y_pred_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [20:43:33] src/learner.cc:180: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000001a1e2cf579 dmlc::LogMessageFatal::~LogMessageFatal() + 57\n  [bt] (1) 2   libxgboost.dylib                    0x0000001a1e2d2e70 xgboost::LearnerImpl::ConfigureUpdaters() + 2016\n  [bt] (2) 3   libxgboost.dylib                    0x0000001a1e2ca971 xgboost::LearnerImpl::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 3633\n  [bt] (3) 4   libxgboost.dylib                    0x0000001a1e2ea2eb XGBoosterUpdateOneIter + 139\n  [bt] (4) 5   libffi.6.dylib                      0x000000010db6b884 ffi_call_unix64 + 76\n  [bt] (5) 6   ???                                 0x00007ffee2c21770 0x0 + 140732702791536\n\n"
     ]
    }
   ],
   "source": [
    "# Set algoritm parameters\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=27)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = space_eval(space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-4472c3b60790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m clf = xgb.XGBClassifier(\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtree_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpu_hist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    **best_params,\n",
    "    tree_method='gpu_hist'\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_preds = clf.predict_proba(X_test)[:,1] \n",
    "\n",
    "show_scores(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'decision_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-cd87b4b7815d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maverage_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print('Average precision-recall score: {0:0.2f}'.format(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'decision_function'"
     ]
    }
   ],
   "source": [
    "y_score = clf.decision_function(X_test)\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 57min 51s, sys: 1min 46s, total: 2h 59min 38s\n",
      "Wall time: 15min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "params={'learning_rate': 0.01,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_threads': -1,\n",
    "        'num_leaves': 256,\n",
    "        'verbose': 1,\n",
    "        'random_state': 42,\n",
    "        'bagging_fraction': 1,\n",
    "        'feature_fraction': 0.85\n",
    "       }\n",
    "\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "sub_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "clf = lgb.LGBMClassifier(**params, n_estimators=3000)\n",
    "clf.fit(X_train, y_train)\n",
    "oof_preds = clf.predict_proba(X_train, num_iteration=clf.best_iteration_)[:,1]\n",
    "sub_preds = clf.predict_proba(X_test, num_iteration=clf.best_iteration_)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, oof_preds)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using non-engineered data only\n",
    "\n",
    "Decision Tree\n",
    "\n",
    "XGBoost\n",
    "\n",
    "DNN\n",
    "\n",
    "\n",
    "Using all data\n",
    "\n",
    "\n",
    "Simplifying categorical data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
